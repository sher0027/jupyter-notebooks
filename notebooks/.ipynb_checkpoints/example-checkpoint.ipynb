{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 10790,
     "status": "ok",
     "timestamp": 1743751692538,
     "user": {
      "displayName": "Asher K",
      "userId": "07359585536125632600"
     },
     "user_tz": -480
    },
    "id": "wdBpJkfrYQH0"
   },
   "outputs": [],
   "source": [
    "# from pgmpy.models import DiscreteBayesianNetwork\n",
    "# from pgmpy.inference import VariableElimination\n",
    "# from pgmpy.factors.discrete import TabularCPD\n",
    "import networkx as nx\n",
    "import pymc as pm\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "import aesara.tensor as at\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc.math as pmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ff25fc219d0846438ed03b7361deebfd",
      "e1811e01a77046eabcb7c79ed407ab58"
     ]
    },
    "executionInfo": {
     "elapsed": 47595,
     "status": "ok",
     "timestamp": 1743740201095,
     "user": {
      "displayName": "Asher K",
      "userId": "07359585536125632600"
     },
     "user_tz": -480
    },
    "id": "EbstFwVAkAcQ",
    "outputId": "7388993b-9cfe-40a8-f37f-ad65815390a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: Shape.0\n",
      "p_risk shape: Shape.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "/opt/conda/lib/python3.11/site-packages/multipledispatch/dispatcher.py:27: AmbiguityWarning: \n",
      "Ambiguities exist in dispatched function _unify\n",
      "\n",
      "The following signatures may result in ambiguous behavior:\n",
      "\t[ConstrainedVar, object, Mapping], [object, ConstrainedVar, Mapping]\n",
      "\t[ConstrainedVar, Var, Mapping], [object, ConstrainedVar, Mapping]\n",
      "\t[object, ConstrainedVar, Mapping], [ConstrainedVar, Var, Mapping]\n",
      "\t[ConstrainedVar, object, Mapping], [object, ConstrainedVar, Mapping]\n",
      "\n",
      "\n",
      "Consider making the following additions:\n",
      "\n",
      "@dispatch(ConstrainedVar, ConstrainedVar, Mapping)\n",
      "def _unify(...)\n",
      "\n",
      "@dispatch(ConstrainedVar, ConstrainedVar, Mapping)\n",
      "def _unify(...)\n",
      "\n",
      "@dispatch(ConstrainedVar, ConstrainedVar, Mapping)\n",
      "def _unify(...)\n",
      "\n",
      "@dispatch(ConstrainedVar, ConstrainedVar, Mapping)\n",
      "def _unify(...)\n",
      "  warn(warning_text(dispatcher.name, ambiguities), AmbiguityWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/pytensor/link/c/cmodule.py:2959: UserWarning: PyTensor could not link to a BLAS installation. Operations that might benefit from BLAS will be severely degraded.\n",
      "This usually happens when PyTensor is installed via pip. We recommend it be installed via conda/mamba/pixi instead.\n",
      "Alternatively, you can use an experimental backend such as Numba or JAX that perform their own BLAS optimizations, by setting `pytensor.config.mode == 'NUMBA'` or passing `mode='NUMBA'` when compiling a PyTensor function.\n",
      "For more options and details see https://pytensor.readthedocs.io/en/latest/troubleshooting.html#how-do-i-configure-test-my-blas-library\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "SamplingError",
     "evalue": "Initial evaluation of model at starting point failed!\nStarting values:\n{'sigma_traffic_log__': array(-0.2967922), 'alpha_traffic': array(50.16319594), 'beta_time': array(0.63224658), 'beta_seasonal': array(10.71967818), 'beta_risk_1': array(0.37254216), 'beta_traffic_1': array(0.02103069), 'beta_weather_1': array(0.20002218), 'beta_risk_2': array(0.6554415), 'beta_traffic_2': array(-0.34243432), 'beta_weather_2': array(-0.85977815)}\n\nLogp initial evaluation results:\n{'sigma_traffic': -1.04, 'alpha_traffic': -3.22, 'beta_time': -1.12, 'beta_seasonal': -2.54, 'beta_risk_1': -0.99, 'beta_traffic_1': -0.92, 'beta_weather_1': -0.94, 'beta_risk_2': -1.13, 'beta_traffic_2': -0.98, 'beta_weather_2': -1.29, 'obs_traffic': -123775.25, 'obs_risk': -inf}\nYou can call `model.debug()` for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSamplingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 77\u001b[0m\n\u001b[1;32m     70\u001b[0m     obs_risk \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mCategorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs_risk\u001b[39m\u001b[38;5;124m\"\u001b[39m, p\u001b[38;5;241m=\u001b[39mp_risk, observed\u001b[38;5;241m=\u001b[39mrisk_data)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# 3. Monte Carlo Sampling (MCMC)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# Use Markov Chain Monte Carlo (MCMC) to sample from the posterior distribution\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     trace \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m az\u001b[38;5;241m.\u001b[39mplot_trace(trace)\n\u001b[1;32m     80\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pymc/sampling/mcmc.py:832\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, compile_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    830\u001b[0m         [kwargs\u001b[38;5;241m.\u001b[39msetdefault(k, v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m nuts_kwargs\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m joined_blas_limiter():\n\u001b[0;32m--> 832\u001b[0m         initial_points, step \u001b[38;5;241m=\u001b[39m \u001b[43minit_nuts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjitter_max_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjitter_max_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitvals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitvals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompile_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompile_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;66;03m# Get initial points\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     ipfns \u001b[38;5;241m=\u001b[39m make_initial_point_fns_per_chain(\n\u001b[1;32m    848\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    849\u001b[0m         overrides\u001b[38;5;241m=\u001b[39minitvals,\n\u001b[1;32m    850\u001b[0m         jitter_rvs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mset\u001b[39m(),\n\u001b[1;32m    851\u001b[0m         chains\u001b[38;5;241m=\u001b[39mchains,\n\u001b[1;32m    852\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pymc/sampling/mcmc.py:1605\u001b[0m, in \u001b[0;36minit_nuts\u001b[0;34m(init, chains, n_init, model, random_seed, progressbar, jitter_max_retries, tune, initvals, compile_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1602\u001b[0m     q, _ \u001b[38;5;241m=\u001b[39m DictToArrayBijection\u001b[38;5;241m.\u001b[39mmap(ip)\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logp_dlogp_func([q], extra_vars\u001b[38;5;241m=\u001b[39m{})[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1605\u001b[0m initial_points \u001b[38;5;241m=\u001b[39m \u001b[43m_init_jitter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitvals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjitter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjitter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjitter_max_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjitter_max_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogp_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_logp_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1614\u001b[0m apoints \u001b[38;5;241m=\u001b[39m [DictToArrayBijection\u001b[38;5;241m.\u001b[39mmap(point) \u001b[38;5;28;01mfor\u001b[39;00m point \u001b[38;5;129;01min\u001b[39;00m initial_points]\n\u001b[1;32m   1615\u001b[0m apoints_data \u001b[38;5;241m=\u001b[39m [apoint\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mfor\u001b[39;00m apoint \u001b[38;5;129;01min\u001b[39;00m apoints]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pymc/sampling/mcmc.py:1486\u001b[0m, in \u001b[0;36m_init_jitter\u001b[0;34m(model, initvals, seeds, jitter, jitter_max_retries, logp_fn)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(point_logp):\n\u001b[1;32m   1484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m jitter_max_retries:\n\u001b[1;32m   1485\u001b[0m         \u001b[38;5;66;03m# Print informative message on last attempted point\u001b[39;00m\n\u001b[0;32m-> 1486\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_start_vals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;66;03m# Retry with a new seed\u001b[39;00m\n\u001b[1;32m   1488\u001b[0m     seed \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mintegers(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pymc/model/core.py:1778\u001b[0m, in \u001b[0;36mModel.check_start_vals\u001b[0;34m(self, start, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m initial_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoint_logps(point\u001b[38;5;241m=\u001b[39melem, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(np\u001b[38;5;241m.\u001b[39misfinite(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m initial_eval\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 1778\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SamplingError(\n\u001b[1;32m   1779\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial evaluation of model at starting point failed!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1780\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00melem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogp initial evaluation results:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00minitial_eval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can call `model.debug()` for more details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1783\u001b[0m     )\n",
      "\u001b[0;31mSamplingError\u001b[0m: Initial evaluation of model at starting point failed!\nStarting values:\n{'sigma_traffic_log__': array(-0.2967922), 'alpha_traffic': array(50.16319594), 'beta_time': array(0.63224658), 'beta_seasonal': array(10.71967818), 'beta_risk_1': array(0.37254216), 'beta_traffic_1': array(0.02103069), 'beta_weather_1': array(0.20002218), 'beta_risk_2': array(0.6554415), 'beta_traffic_2': array(-0.34243432), 'beta_weather_2': array(-0.85977815)}\n\nLogp initial evaluation results:\n{'sigma_traffic': -1.04, 'alpha_traffic': -3.22, 'beta_time': -1.12, 'beta_seasonal': -2.54, 'beta_risk_1': -0.99, 'beta_traffic_1': -0.92, 'beta_weather_1': -0.94, 'beta_risk_2': -1.13, 'beta_traffic_2': -0.98, 'beta_weather_2': -1.29, 'obs_traffic': -123775.25, 'obs_risk': -inf}\nYou can call `model.debug()` for more details."
     ]
    }
   ],
   "source": [
    "# Build PyMC model\n",
    "# Simulate data\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "time = np.arange(n_samples)\n",
    "\n",
    "# Simulated traffic data with a periodic pattern\n",
    "traffic_data = 50 + 10 * np.sin(2 * np.pi * time / 24) + np.random.normal(0, 5, n_samples)\n",
    "# Simulated weather data (binary: 0 = Bad Weather, 1 = Good Weather)\n",
    "weather_data = np.random.binomial(1, 0.2, n_samples)  # 20% chance of good weather\n",
    "# Simulated risk data (0 = Low, 1 = Medium, 2 = High)\n",
    "risk_data = np.random.choice([0, 1, 2], size=n_samples, p=[0.6, 0.3, 0.1])\n",
    "\n",
    "with pm.Model() as model:\n",
    "\n",
    "    # -------------------------\n",
    "    # 1. Time Series Modeling for Traffic Forecasting\n",
    "    # -------------------------\n",
    "\n",
    "    # Prior for traffic fluctuation (uncertainty in the model)\n",
    "    sigma_traffic = pm.Exponential(\"sigma_traffic\", 1.0)\n",
    "\n",
    "    # Priors for the trend and seasonal effects\n",
    "    alpha_traffic = pm.Normal(\"alpha_traffic\", mu=50, sigma=10)  # Baseline traffic level\n",
    "    beta_time = pm.Normal(\"beta_time\", mu=0, sigma=1)  # Trend effect (increase or decrease over time)\n",
    "    beta_seasonal = pm.Normal(\"beta_seasonal\", mu=10, sigma=5)  # Seasonal effect (e.g., daily peaks)\n",
    "\n",
    "    # Traffic forecast equation: Trend + Seasonality\n",
    "    mu_traffic = alpha_traffic + beta_time * time + beta_seasonal * pm.math.sin(2 * np.pi * time / 24)\n",
    "\n",
    "    # Observed traffic data modeled as a normal distribution\n",
    "    obs_traffic = pm.Normal(\"obs_traffic\", mu=mu_traffic, sigma=sigma_traffic, observed=traffic_data)\n",
    "    \n",
    "    # -------------------------\n",
    "    # 2. Logistic Regression for Risk Prediction\n",
    "    # -------------------------\n",
    "\n",
    "    # Priors for risk prediction model\n",
    "    # Coefficients for each class (except the reference class, which is 0)\n",
    "    beta_risk_1 = pm.Normal(\"beta_risk_1\", mu=0, sigma=1)\n",
    "    beta_traffic_1 = pm.Normal(\"beta_traffic_1\", mu=0, sigma=1)\n",
    "    beta_weather_1 = pm.Normal(\"beta_weather_1\", mu=0, sigma=1)\n",
    "\n",
    "    beta_risk_2 = pm.Normal(\"beta_risk_2\", mu=0, sigma=1)\n",
    "    beta_traffic_2 = pm.Normal(\"beta_traffic_2\", mu=0, sigma=1)\n",
    "    beta_weather_2 = pm.Normal(\"beta_weather_2\", mu=0, sigma=1)\n",
    "\n",
    "    # Linear predictors for Medium (1) and High (2) risk\n",
    "    traffic_data_shared = pm.Data(\"traffic_data\", traffic_data)\n",
    "    weather_data_shared = pm.Data(\"weather_data\", weather_data)\n",
    "    \n",
    "    logits_1 = beta_risk_1 + beta_traffic_1 * traffic_data_shared + beta_weather_1 * weather_data_shared\n",
    "    logits_2 = beta_risk_2 + beta_traffic_2 * traffic_data_shared + beta_weather_2 * weather_data_shared\n",
    "\n",
    "    # Ensure logits_1 and logits_2 have the same shape as logits_0 for concatenation\n",
    "    logits_1_r = pmm.broadcast_to(logits_1[:, None], (n_samples, 1))  # Equivalent to reshaping (n_samples, 1)\n",
    "    logits_2_r = pmm.broadcast_to(logits_2[:, None], (n_samples, 1))  # Equivalent to reshaping (n_samples, 1)\n",
    "    \n",
    "    logits_0 = pmm.zeros((n_samples, 1), dtype=logits_1.dtype)\n",
    "    \n",
    "    # Concatenate logits_0, logits_1_r, logits_2_r\n",
    "    logits = pmm.concatenate([logits_0, logits_1_r, logits_2_r], axis=1)\n",
    "    print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "    # Apply softmax to get class probabilities\n",
    "    p_risk = pmm.softmax(logits)\n",
    "    print(\"p_risk shape:\", p_risk.shape)\n",
    "\n",
    "    # Observed risk data\n",
    "    obs_risk = pm.Categorical(\"obs_risk\", p=p_risk, observed=risk_data)\n",
    "\n",
    "    # -------------------------\n",
    "    # 3. Monte Carlo Sampling (MCMC)\n",
    "    # -------------------------\n",
    "\n",
    "    # Use Markov Chain Monte Carlo (MCMC) to sample from the posterior distribution\n",
    "    trace = pm.sample(5000, return_inferencedata=True, target_accept=0.95)\n",
    "\n",
    "az.plot_trace(trace)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1743733734109,
     "user": {
      "displayName": "Asher K",
      "userId": "07359585536125632600"
     },
     "user_tz": -480
    },
    "id": "x-t_GIrNYvFt",
    "outputId": "f388d7f5-2e4b-44fb-dea3-8c40790f7359"
   },
   "outputs": [],
   "source": [
    "# Forecasting Traffic for Future Periods\n",
    "\n",
    "# Generate future time points (next 12 days)\n",
    "forecast_x = np.arange(len(traffic_data), len(traffic_data) + 12)\n",
    "\n",
    "# Extract posterior samples\n",
    "alpha_samples = trace.posterior[\"alpha_traffic\"].stack(sample=(\"chain\", \"draw\")).values\n",
    "beta_time_samples = trace.posterior[\"beta_time\"].stack(sample=(\"chain\", \"draw\")).values\n",
    "beta_seasonal_samples = trace.posterior[\"beta_seasonal\"].stack(sample=(\"chain\", \"draw\")).values\n",
    "\n",
    "# Compute forecast mean (for line plot)\n",
    "alpha_mean = alpha_samples.mean()\n",
    "beta_time_mean = beta_time_samples.mean()\n",
    "beta_seasonal_mean = beta_seasonal_samples.mean()\n",
    "forecast_y = alpha_mean + beta_time_mean * forecast_x + beta_seasonal_mean * np.sin(2 * np.pi * forecast_x / 24)\n",
    "\n",
    "# Compute forecast samples for credible interval\n",
    "N = alpha_samples.shape[0]\n",
    "forecast_x_expanded = np.tile(forecast_x, (N, 1))\n",
    "forecast_samples = (\n",
    "    alpha_samples[:, None] +\n",
    "    beta_time_samples[:, None] * forecast_x_expanded +\n",
    "    beta_seasonal_samples[:, None] * np.sin(2 * np.pi * forecast_x_expanded / 24)\n",
    ")\n",
    "\n",
    "# Compute 95% credible interval\n",
    "forecast_low = np.percentile(forecast_samples, 2.5, axis=0)\n",
    "forecast_high = np.percentile(forecast_samples, 97.5, axis=0)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(time, traffic_data, label=\"Observed Traffic\", color=\"b\")\n",
    "plt.plot(forecast_x, forecast_y, label=\"Forecast Traffic\", linestyle=\"dashed\", color=\"g\")\n",
    "plt.fill_between(forecast_x, forecast_low, forecast_high, color=\"g\", alpha=0.3, label=\"95% CI\")\n",
    "plt.legend()\n",
    "plt.title(\"Traffic Forecast using PyMC with 95% Credible Interval\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Traffic Level\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99muWv4lYfvd"
   },
   "outputs": [],
   "source": [
    "# Define the Bayesian Network structure\n",
    "# Creates a Bayesian network model named 'model' with the specified dependencies:\n",
    "# Traffic and Weather directly influence Risk.\n",
    "# Traffic directly influences AirQuality.\n",
    "# AirQuality also influences Risk.\n",
    "model = DiscreteBayesianNetwork([('Traffic', 'Risk'), ('Weather', 'Risk'), ('Traffic', 'AirQuality'), ('AirQuality', 'Risk')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNb0IJVIYnpJ"
   },
   "outputs": [],
   "source": [
    "# Define the Conditional Probability Distributions (CPDs)\n",
    "# CPDs specify the probability of each state of a variable given the states of its parents.\n",
    "# variable: The name of the variable.\n",
    "# variable_card: The number of possible states for the variable.\n",
    "# values: A list of lists representing the probabilities. The order matters and depends on the evidence.\n",
    "# evidence: A list of the parent variables.\n",
    "# evidence_card: A list of the number of states for each parent variable (in the same order as 'evidence').\n",
    "ram = {\n",
    "    ('Low', 'Good', 0): [0.85, 0.10, 0.05],  # Low T, Good W, AQ=0: Low, Med, High\n",
    "    ('Low', 'Good', 1): [0.75, 0.20, 0.05],  # Low T, Good W, AQ=1: Low, Med, High\n",
    "    ('Low', 'Bad', 0):  [0.55, 0.35, 0.10],  # Low T, Bad W, AQ=0: Low, Med, High\n",
    "    ('Low', 'Bad', 1):  [0.45, 0.45, 0.10],  # Low T, Bad W, AQ=1: Low, Med, High\n",
    "    ('High', 'Good', 0): [0.65, 0.25, 0.10], # High T, Good W, AQ=0: Low, Med, High\n",
    "    ('High', 'Good', 1): [0.55, 0.35, 0.10], # High T, Good W, AQ=1: Low, Med, High\n",
    "    ('High', 'Bad', 0):  [0.25, 0.45, 0.30], # High T, Bad W, AQ=0: Low, Med, High\n",
    "    ('High', 'Bad', 1):  [0.15, 0.55, 0.30], # High T, Bad W, AQ=1: Low, Med, High\n",
    "}\n",
    "\n",
    "# Define the order of evidence states for the columns in 'values'\n",
    "evidence_order = [('Low', 'Good', 0), ('High', 'Good', 0), ('Low', 'Bad', 0), ('High', 'Bad', 0),\n",
    "                  ('Low', 'Good', 1), ('High', 'Good', 1), ('Low', 'Bad', 1), ('High', 'Bad', 1)]\n",
    "\n",
    "ram_values = np.array([list(ram[key]) for key in evidence_order]).T\n",
    "cpd_traffic = TabularCPD(variable='Traffic', variable_card=2, values=[[0.7], [0.3]])\n",
    "cpd_weather = TabularCPD(variable='Weather', variable_card=2, values=[[0.8], [0.2]])\n",
    "cpd_air_quality = TabularCPD(variable='AirQuality', variable_card=2,\n",
    "                             values=[[0.9, 0.6],  # P(AQ=0 | T=0, T=1)\n",
    "                                     [0.1, 0.4]],\n",
    "                             evidence=['Traffic'], evidence_card=[2])\n",
    "cpd_risk = TabularCPD(variable='Risk', variable_card=3,\n",
    "                     values=ram_values,\n",
    "                     evidence=['Traffic', 'Weather', 'AirQuality'], evidence_card=[2, 2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743734728803,
     "user": {
      "displayName": "Asher K",
      "userId": "07359585536125632600"
     },
     "user_tz": -480
    },
    "id": "5X4WSTqTYrCy",
    "outputId": "115e38fb-6830-4b85-8caa-0ac9b5cb6537"
   },
   "outputs": [],
   "source": [
    "# Add CPDs to the model\n",
    "model.add_cpds(cpd_traffic, cpd_weather, cpd_air_quality, cpd_risk)\n",
    "model.check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1743734729859,
     "user": {
      "displayName": "Asher K",
      "userId": "07359585536125632600"
     },
     "user_tz": -480
    },
    "id": "ysPk9kI1d5JX",
    "outputId": "aab871d5-76a1-4974-8eae-a1ad0047f583"
   },
   "outputs": [],
   "source": [
    "# Visualize the DAG\n",
    "pos = nx.circular_layout(model)\n",
    "nx.draw(model, pos=pos, with_labels=True)\n",
    "plt.title(\"Bayesian Network Structure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eh-HJ1IvYuTI"
   },
   "outputs": [],
   "source": [
    "# Perform inference\n",
    "predicted_risks = { 'Low': [], 'Medium': [], 'High': [] }\n",
    "inference = VariableElimination(model)\n",
    "threshold = 60\n",
    "forecast_traffic_states = (forecast_samples > threshold).astype(int)\n",
    "\n",
    "for i in range(forecast_traffic_states.shape[1]):\n",
    "    traffic_states_for_day = forecast_traffic_states[:, i]\n",
    "    predicted_risk_for_day = {'Low': [], 'Medium': [], 'High': []}\n",
    "\n",
    "    for traffic_state in traffic_states_for_day:\n",
    "        predicted_risk = inference.query(\n",
    "            variables=['Risk'],\n",
    "            evidence={'Traffic': traffic_state, 'Weather': 1, 'AirQuality': 0}\n",
    "        )\n",
    "\n",
    "        # Append probabilities for Low, Medium, and High\n",
    "        predicted_risk_for_day['Low'].append(predicted_risk.values[0])  # Low risk\n",
    "        predicted_risk_for_day['Medium'].append(predicted_risk.values[1])  # Medium risk\n",
    "        predicted_risk_for_day['High'].append(predicted_risk.values[2])  # High risk\n",
    "\n",
    "    # Append each day's risk probabilities\n",
    "    for risk_level in predicted_risk_for_day:\n",
    "        predicted_risks[risk_level].append(np.mean(predicted_risk_for_day[risk_level]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1743739343206,
     "user": {
      "displayName": "Asher K",
      "userId": "07359585536125632600"
     },
     "user_tz": -480
    },
    "id": "Yj2943R488Ao",
    "outputId": "ae568508-dd7c-43ef-817a-e9610b80f31c"
   },
   "outputs": [],
   "source": [
    "# Plot all risk levels in one chart\n",
    "plt.figure(figsize=(6, 10))\n",
    "for risk_level in predicted_risks:\n",
    "    plt.plot(forecast_x, predicted_risks[risk_level], marker='o', linestyle='-', label=f\"{risk_level} Risk\")\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Risk Probability\")\n",
    "plt.title(\"Predicted Risk over Time\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNlcIeWDFmgUoCI7jX7hXI8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "e1811e01a77046eabcb7c79ed407ab58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff25fc219d0846438ed03b7361deebfd": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_e1811e01a77046eabcb7c79ed407ab58",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                  </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   6000    0             0.18        15           283.67 draws/s   0:00:21   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   6000    0             0.15        31           138.03 draws/s   0:00:43   0:00:00    \n                                                                                                                   \n</pre>\n",
         "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                 \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   6000    0             0.18        15           283.67 draws/s   0:00:21   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   6000    0             0.15        31           138.03 draws/s   0:00:43   0:00:00    \n                                                                                                                   \n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
